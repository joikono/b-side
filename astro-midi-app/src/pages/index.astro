---
// index.astro - Frontend-Only MIDI Analysis Demo with Integrated Player
// Perfect audio quality with Web MIDI API + Web Audio API + MIDI Playback
const title = "üéπ Live MIDI Analysis Demo";
const apiBase = "http://localhost:8000";
import CircularWaveform from '../components/circular_waveform.astro';
---

<html lang="en">
<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>{title}</title>
    
    <!-- Load the proven html-midi-player library -->
    <script src="https://cdn.jsdelivr.net/combine/npm/tone@14.7.58,npm/@magenta/music@1.23.1/es6/core.js,npm/focus-visible@5,npm/html-midi-player@1.4.0"></script>
</head>
<body>
    <main>
        <h1>{title}</h1>
        
        <!-- Device Connection Section -->
        <section class="section">
            <h3>1. Connect MIDI Device</h3>
            <select id="deviceSelect">
                <option>Loading devices...</option>
            </select>
            <button class="connect-btn" onclick="connectDevice()">Connect Device</button>
            <button onclick="loadDevices()">üîÑ Refresh Devices</button>
            <div id="midiStatus" class="status ready">Ready to connect</div>
            
            <!-- Piano Sound Controls -->
            <div id="pianoControls" style="display: none; margin-top: 15px;">
                <label>
                    Piano Volume: 
                    <input type="range" id="pianoVolume" min="0" max="100" value="15">
                    <span id="volumeValue">15%</span>
                </label>
                <br>
                <label>
                    Piano Sound: 
                    <select id="pianoSound">
                        <option value="piano">Piano</option>
                        <option value="electric">Electric Piano</option>
                        <option value="organ">Organ</option>
                        <option value="synth">Synth</option>
                    </select>
                </label>
                <br>
            </div>
        </section>
        <!-- NEW: Dedicated Audio Visualizer Section -->
        <section class="section visualizer-section">
            <h3>üåä Real-time Audio Visualizer</h3>
            <p>Live visualization of your MIDI performance - connect a device and start playing!</p>
            
            <div class="visualizer-container">
                <CircularWaveform 
                    height="320px" 
                    showControls={false}
                    className="midi-spectrum main-visualizer"
                />
                
                <div class="visualizer-status" id="visualizerStatus">
                    <span class="status-dot" id="audioStatusDot"></span>
                    <span id="audioStatusText">Waiting for MIDI connection...</span>
                    <button onclick="retryVisualizerConnection()" id="retryBtn" style="display: none;">üîÑ Retry</button>
                </div>
            </div>
        </section>
        
        <!-- Capture Controls Section -->
        <section class="section">
            <h3>2. Record Your Melody</h3>
            <label>
                Capture Mode: 
                <select id="captureMode">
                    <option value="time">Fixed Duration (9.6 seconds)</option>
                    <option value="silence">Until Silence (2 seconds)</option>
                    <option value="manual">Manual Stop</option>
                </select>
            </label>
            <br>
            <div class="button-group">
                <button class="record-btn" onclick="startCapture()">üéπ Start Recording</button>
                <button class="stop-btn" onclick="stopCapture()">‚èπÔ∏è Stop Recording</button>
            </div>
            <div id="captureStatus" class="status ready">Ready to record</div>
            <div id="beatIndicator" class="beat-indicator">
                <div class="beat-circle" id="beatCircle"></div>
                <div class="beat-count" id="beatCount">Ready</div>
            </div>
        </section>
        
        <!-- Results Section - Moved here so user doesn't have to scroll -->
        <section class="section results" id="results" style="display: none;">
            <h3>üéµ Analysis Results</h3>
            <div id="keyInfo"></div>
            <div id="progressions"></div>
            <div id="arrangementLink"></div>
            <div id="visualizationLink" class="visualization"></div>
            
            <!-- Integrated MIDI Player -->
            <div id="midiPlayerSection" class="midi-player-section" style="display: none;">
                <h4>üéµ Play Your Generated Arrangement</h4>
                <p>Listen to your AI-generated arrangement with seamless 16-beat looping</p>
                
                <div class="player-container">
                    <!-- MIDI player with native loop attribute -->
                    <midi-player 
                        id="arrangementPlayer"
                        src="" 
                        sound-font="https://storage.googleapis.com/magentadata/js/soundfonts/sgm_plus"
                        visualizer="#myVisualizer"
                        loop>
                    </midi-player>                
                    <!-- Custom controls for the player -->
                    <div class="midi-controls">
                        <div class="button-row">
                            <button onclick="toggleMidiPlay()" class="midi-btn">‚èØÔ∏è Play/Pause</button>
                            <button onclick="stopMidi()" class="midi-btn">‚èπÔ∏è Stop</button>
                            <button onclick="toggleMidiLoop()" class="midi-btn">üîÑ <span id="midiLoopStatus">Loop: OFF</span></button>
                        </div>
                        
                        <div class="midi-debug-info">
                            <h5>üîç Playback Info:</h5>
                            <div id="midiPlayerInfo">Player ready...</div>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        
        <!-- Analysis Options Section -->
        <section class="section">
            <h3>3. Generate Full Arrangement</h3>
            <label>
                Harmonization Style: 
                <select id="harmonyStyle">
                    <option value="simple_pop">Simple/Pop</option>
                    <option value="folk_acoustic">Folk/Acoustic</option>
                    <option value="bass_foundation">Bass Foundation</option>
                    <option value="phrase_foundation">Phrase Foundation</option>
                </select>
            </label>
            <br>
            <label>
                Bass Complexity: 
                <input type="range" id="bassComplexity" min="1" max="3" value="1"> 
                <span id="bassValue">1</span>
            </label>
            <br>
            <label>
                Drum Complexity: 
                <input type="range" id="drumComplexity" min="1" max="3" value="1"> 
                <span id="drumValue">1</span>
            </label>
            <br>
            
            <div class="button-group">
                <button class="analyze-btn" onclick="analyzeAndGenerate()">üéº Generate Full Arrangement</button>
            </div>
            <div id="analysisStatus" class="status ready">Ready to generate arrangement</div>
        </section>

    </main>
</body>
</html>

<style>
    /* Global Styles */
    * {
        box-sizing: border-box;
    }
    
    body {
        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        max-width: 900px;
        margin: 0 auto;
        padding: 20px;
        background-color: #000000;
        line-height: 1.6;
    }
    
    main {
        background: rgb(39, 13, 82);
        border-radius: 12px;
        padding: 30px;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    
    h1 {
        color: #ffffff;
        text-align: center;
        margin-bottom: 30px;
        font-size: 2.2rem;
    }
    
    h3 {
        color: #ffffff;
        margin-bottom: 15px;
        border-bottom: 2px solid #ecf0f1;
        padding-bottom: 8px;
    }
    
    h4 {
        color: #ffffff;
        margin-bottom: 10px;
        font-size: 1.3rem;
    }
    
    h5 {
        color: #ffffff;
        margin-bottom: 8px;
        font-size: 1rem;
    }
    
    /* Section Styles */
    .section {
        margin: 25px 0;
        padding: 20px;
        border: 1px solid #e1e8ed;
        border-radius: 12px;
        background: #0a69c7;
        transition: box-shadow 0.3s ease;
    }
    
    .section:hover {
        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
    }
    
    /* Button Styles */
    button {
        padding: 12px 18px;
        margin: 5px;
        border: none;
        border-radius: 8px;
        cursor: pointer;
        font-weight: 600;
        transition: all 0.3s ease;
        font-size: 14px;
    }
    
    button:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
    }
    
    button:active {
        transform: translateY(0);
    }
    
    .connect-btn {
        background: linear-gradient(45deg, #4CAF50, #45a049);
        color: white;
    }
    
    .record-btn {
        background: linear-gradient(45deg, #2196F3, #1976D2);
        color: white;
    }
    
    .stop-btn {
        background: linear-gradient(45deg, #f44336, #d32f2f);
        color: white;
    }
    
    .analyze-btn {
        background: linear-gradient(45deg, #FF9800, #f57c00);
        color: white;
    }
    
    .melody-btn {
        background: linear-gradient(45deg, #9C27B0, #7b1fa2);
        color: white;
    }
    
    .midi-btn {
        background: linear-gradient(45deg, #00BCD4, #0097A7);
        color: white;
        font-size: 16px;
        font-weight: bold;
    }
    
    /* Form Controls */
    select, input[type="range"] {
        padding: 10px;
        margin: 8px 5px;
        border: 2px solid #ddd;
        border-radius: 6px;
        font-size: 14px;
        transition: border-color 0.3s ease;
    }
    
    select:focus, input:focus {
        outline: none;
        border-color: #4CAF50;
        box-shadow: 0 0 0 3px rgba(76, 175, 80, 0.1);
    }
    
    input[type="range"] {
        -webkit-appearance: none;
        height: 8px;
        border-radius: 4px;
        background: #ddd;
        outline: none;
    }
    
    input[type="range"]::-webkit-slider-thumb {
        -webkit-appearance: none;
        appearance: none;
        width: 20px;
        height: 20px;
        border-radius: 50%;
        background: #4CAF50;
        cursor: pointer;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.2);
    }
    
    input[type="range"]::-moz-range-thumb {
        width: 20px;
        height: 20px;
        border-radius: 50%;
        background: #4CAF50;
        cursor: pointer;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.2);
        border: none;
    }
    
    label {
        display: block;
        margin: 10px 0;
        font-weight: 500;
        color: #ffffff;
    }
    
    /* Status Styles */
    .status {
        padding: 12px;
        margin: 15px 0;
        border-radius: 8px;
        font-weight: 500;
        border-left: 4px solid #ccc;
        transition: all 0.3s ease;
    }
    
    .status.ready {
        background: linear-gradient(135deg, #e8f5e8, #f0f8f0);
        border-left-color: #4CAF50;
        color: #2e7d32;
    }
    
    .status.recording {
        background: linear-gradient(135deg, #fff3cd, #fdf6d8);
        border-left-color: #ff9800;
        color: #e65100;
        animation: pulse 2s infinite;
    }
    
    .status.analyzing {
        background: linear-gradient(135deg, #d1ecf1, #e3f2fd);
        border-left-color: #2196F3;
        color: #0277bd;
    }
    
    .status.error {
        background: linear-gradient(135deg, #f8d7da, #fce4e6);
        border-left-color: #f44336;
        color: #c62828;
    }
    
    @keyframes pulse {
        0%, 100% { opacity: 1; }
        50% { opacity: 0.7; }
    }
    
    /* Results Styles */
    .results {
        background: linear-gradient(135deg, #f5f7fa, #c3cfe2);
    }
    
    .chord-progression {
        font-family: 'Courier New', monospace;
        font-size: 16px;
        background: #2c3e50;
        color: #ecf0f1;
        padding: 15px;
        margin: 10px 0;
        border-radius: 8px;
        border-left: 4px solid #3498db;
        overflow-x: auto;
        white-space: nowrap;
    }
    
    .button-group {
        margin: 15px 0;
        display: flex;
        flex-wrap: wrap;
        gap: 10px;
    }
    
    .visualization {
        margin: 15px 0;
        padding: 15px;
        background: #fff;
        border-radius: 8px;
        border: 1px solid #e1e8ed;
    }
    
    /* MIDI Player Styles */
    .midi-player-section {
        margin-top: 30px;
        padding: 25px;
        background: linear-gradient(135deg, #02253b, #000000);
        border-radius: 15px;
        border: 2px solid #2196F3;
        box-shadow: 0 4px 12px rgba(33, 150, 243, 0.2);
    }
    
    .player-container {
        display: flex;
        flex-direction: column;
        gap: 20px;
    }
    
    midi-player {
        background: rgba(255, 255, 255, 0.9);
        border-radius: 12px;
        padding: 20px;
        border: 1px solid rgba(33, 150, 243, 0.3);
        display: block;
        margin-bottom: 15px;
        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
    }
    
    midi-visualizer {
        background: rgba(0, 0, 0, 0.05);
        border-radius: 12px;
        padding: 15px;
        border: 1px solid rgba(33, 150, 243, 0.3);
        min-height: 200px;
        display: block;
        box-shadow: inset 0 2px 4px rgba(0, 0, 0, 0.1);
    }
    
    .midi-controls {
        background: rgba(255, 255, 255, 0.8);
        border-radius: 12px;
        padding: 20px;
        border: 1px solid rgba(33, 150, 243, 0.3);
        display: flex;
        flex-direction: column;
        gap: 15px;
    }
    
    .midi-debug-info {
        background: rgba(0, 0, 0, 0.05);
        padding: 15px;
        border-radius: 8px;
        margin-top: 15px;
    }
    
    #midiPlayerInfo {
        font-family: 'Courier New', monospace;
        font-size: 0.9rem;
        color: #2c3e50;
        background: #f8f9fa;
        padding: 10px;
        border-radius: 5px;
        min-height: 60px;
        max-height: 200px;
        overflow-y: auto;
        border: 1px solid #dee2e6;
    }
    
    /* Responsive Design */
    @media (max-width: 600px) {
        body {
            padding: 10px;
        }
        
        main {
            padding: 20px;
        }
        
        h1 {
            font-size: 1.8rem;
        }
        
        .button-group {
            flex-direction: column;
        }
        
        button {
            width: 100%;
        }
        
        .chord-progression {
            font-size: 14px;
        }
    }
    
    /* Accessibility */
    @media (prefers-reduced-motion: reduce) {
        * {
            animation-duration: 0.01ms !important;
            animation-iteration-count: 1 !important;
            transition-duration: 0.01ms !important;
        }
    }
    
    /* Focus indicators for keyboard navigation */
    button:focus-visible,
    select:focus-visible,
    input:focus-visible {
        outline: 3px solid #4CAF50;
        outline-offset: 2px;
    }
    
    /* Metronome Styles */
    .beat-indicator {
        display: flex;
        flex-direction: column;
        align-items: center;
        margin: 20px 0;
        padding: 20px;
        background: linear-gradient(135deg, #f8f9fa, #e9ecef);
        border-radius: 12px;
        border: 2px solid #dee2e6;
    }
    
    .beat-circle {
        width: 80px;
        height: 80px;
        border-radius: 50%;
        background: linear-gradient(135deg, #6c757d, #495057);
        margin-bottom: 10px;
        transition: all 0.1s ease;
        display: flex;
        align-items: center;
        justify-content: center;
        box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
    }
    
    .beat-circle.active {
        background: linear-gradient(135deg, #28a745, #20c997);
        transform: scale(1.1);
        box-shadow: 0 6px 20px rgba(40, 167, 69, 0.4);
    }
    
    .beat-circle.count-in {
        background: linear-gradient(135deg, #ffc107, #fd7e14);
        transform: scale(1.2);
        box-shadow: 0 6px 20px rgba(255, 193, 7, 0.4);
    }
    
    .beat-count {
        font-size: 18px;
        font-weight: bold;
        color: #495057;
        min-height: 22px;
        text-align: center;
    }
    
    .beat-count.count-in {
        font-size: 24px;
        color: #e67e22;
        animation: pulse-count 0.6s ease-in-out;
    }
    
    .beat-count.recording {
        color: #28a745;
    }
    
    @keyframes pulse-count {
        0% { transform: scale(1); }
        50% { transform: scale(1.2); }
        100% { transform: scale(1); }
    }
    
    /* Checkbox styling */
    input[type="checkbox"] {
        width: 18px;
        height: 18px;
        margin-right: 8px;
        cursor: pointer;
    }

    /* MIDI Spectrum Integration */
    .midi-spectrum {
    --spectrum-accent: #ff9500;
    --spectrum-bg: linear-gradient(135deg, #1a0a2e 0%, #16213e 100%);
    border: 1px solid rgba(255, 149, 0, 0.3);
    }

    .midi-spectrum .circular-spectrum-container {
    border-radius: 8px;
    }
</style>

<script>
    // API Configuration
    const API_BASE = 'http://localhost:8000';
    
    // Global variables
    let metronome;
    let pianoSynth;
    let midiAccess;
    let midiInput;
    let midiRecorder;
    let spectrumInstance = null;
    
    // MIDI Player variables
    let midiPlayer;
    let isMidiLooping = false;
    let baseBPM = 100;
    const defaultBPM = 120;
    const beatsPerLoop = 16;
    let midiCheckLoopInterval;

    // Visualizer Functions
    function retryVisualizerConnection() {
        console.log('üîÑ Manual retry requested');
        updateVisualizerStatus('waiting', 'Retrying connection...');
        spectrumInstance = null;
        
        setTimeout(() => {
            if (connectMidiToSpectrum()) {
                console.log('‚úÖ Manual retry successful');
            } else {
                console.log('‚ùå Manual retry failed');
                updateVisualizerStatus('error', 'Manual retry failed - check console');
            }
        }, 500);
    }

    function updateVisualizerStatus(status, message) {
        const statusDot = document.getElementById('audioStatusDot');
        const statusText = document.getElementById('audioStatusText');
        const retryBtn = document.getElementById('retryBtn');
        
        if (statusDot && statusText) {
            statusDot.classList.remove('connected', 'active');
            
            switch (status) {
                case 'connected':
                    statusDot.classList.add('connected');
                    if (retryBtn) retryBtn.style.display = 'none';
                    break;
                case 'active':
                    statusDot.classList.add('active');
                    if (retryBtn) retryBtn.style.display = 'none';
                    break;
                case 'error':
                    if (retryBtn) retryBtn.style.display = 'inline-block';
                    break;
                case 'waiting':
                default:
                    if (retryBtn) retryBtn.style.display = 'none';
                    break;
            }
            
            statusText.textContent = message;
        }
    }

    function connectMidiToSpectrum() {
        console.log('üîç Starting connectMidiToSpectrum...');
        
        if (!spectrumInstance) {
            const containers = document.querySelectorAll('.circular-spectrum-container');
            console.log('üîç Found spectrum containers:', containers.length);
            
            for (let i = 0; i < containers.length; i++) {
                const container = containers[i];
                if (container.spectrumInstance) {
                    spectrumInstance = container.spectrumInstance;
                    console.log('‚úÖ Found spectrum instance in container', i);
                    break;
                }
            }
        }
        
        if (!spectrumInstance || !pianoSynth || !pianoSynth.audioContext) {
            const missing = [];
            if (!spectrumInstance) missing.push('spectrumInstance');
            if (!pianoSynth) missing.push('pianoSynth');
            if (!pianoSynth?.audioContext) missing.push('audioContext');
            
            console.log('‚è≥ Missing components:', missing);
            updateVisualizerStatus('waiting', `Missing: ${missing.join(', ')}`);
            return false;
        }
        
        try {
            const tapGain = pianoSynth.audioContext.createGain();
            tapGain.gain.value = 1.0;
            
            pianoSynth.masterGain.connect(tapGain);
            
            if (!spectrumInstance.audioContext) {
                spectrumInstance.audioContext = pianoSynth.audioContext;
            }
            
            if (!spectrumInstance.analyser) {
                spectrumInstance.analyser = pianoSynth.audioContext.createAnalyser();
                spectrumInstance.analyser.fftSize = 512;
                spectrumInstance.analyser.smoothingTimeConstant = 0.8;
            }
            
            tapGain.connect(spectrumInstance.analyser);
            spectrumInstance.dataArray = new Uint8Array(spectrumInstance.analyser.frequencyBinCount);
            spectrumInstance.isAudioActive = true;
            
            if (typeof spectrumInstance.setStatusActive === 'function') {
                spectrumInstance.setStatusActive(true);
            }
            
            if (typeof spectrumInstance.updateStatus === 'function') {
                spectrumInstance.updateStatus('MIDI Connected');
            }
            
            updateVisualizerStatus('connected', 'MIDI audio connected - play some notes!');
            console.log('üéπ MIDI audio connected to spectrum successfully');
            return true;
            
        } catch (error) {
            console.error('‚ùå Failed to connect MIDI to spectrum:', error);
            updateVisualizerStatus('error', `Connection failed: ${error.message}`);
            return false;
        }
    }

    function findSpectrumInstance(attempt = 1) {
        console.log(`üîç Spectrum detection attempt ${attempt}...`);
        
        const containers = document.querySelectorAll('.circular-spectrum-container');
        console.log(`üîç Found ${containers.length} spectrum containers`);
        
        for (let i = 0; i < containers.length; i++) {
            const container = containers[i];
            if (container.spectrumInstance) {
                spectrumInstance = container.spectrumInstance;
                console.log('üåä Spectrum instance found and ready for MIDI connection');
                updateVisualizerStatus('waiting', 'Spectrum ready - connect MIDI device');
                return true;
            }
        }
        
        if (attempt < 5) {
            console.log(`‚è≥ Spectrum not ready, retry ${attempt + 1}/5 in 1 second...`);
            updateVisualizerStatus('waiting', `Loading visualizer... (${attempt}/5)`);
            setTimeout(() => findSpectrumInstance(attempt + 1), 1000);
        } else {
            console.log('‚ùå Spectrum instance not found after 5 attempts');
            updateVisualizerStatus('error', 'Visualizer failed to load - try refresh');
        }
        
        return false;
    }

    async function connectDevice() {
        const deviceSelect = document.getElementById('deviceSelect');
        if (!deviceSelect) return;
        
        const deviceId = deviceSelect.value;
        
        if (!deviceId || deviceId.includes('No MIDI') || deviceId.includes('Error') || deviceId.includes('Web MIDI')) {
            updateStatus('midiStatus', 'Please select a valid MIDI device', 'error');
            return;
        }
        
        if (!midiAccess || !midiAccess.inputs) {
            console.log('üîÑ MIDI access not ready, retrying in 200ms...');
            setTimeout(() => connectDevice(), 200);
            return;
        }
        
        try {
            await pianoSynth.init();
            
            const input = Array.from(midiAccess.inputs.values()).find(inp => inp.id === deviceId);
            
            if (!input) {
                updateStatus('midiStatus', 'Selected MIDI device not found', 'error');
                return;
            }
            
            input.onmidimessage = handleMIDIMessage;
            midiInput = input;
            
            updateStatus('midiStatus', 'üéπ Piano connected! Studio-quality audio enabled', 'ready');
            
            const pianoControls = document.getElementById('pianoControls');
            if (pianoControls) {
                pianoControls.style.display = 'block';
            }
            
            console.log('üéπ Connected to MIDI device:', input.name);

            // Connect to visualizer
            updateVisualizerStatus('waiting', 'Connecting to visualizer...');
            
            setTimeout(() => {
                if (!connectMidiToSpectrum()) {
                    setTimeout(() => {
                        if (!connectMidiToSpectrum()) {
                            setTimeout(() => {
                                if (!connectMidiToSpectrum()) {
                                    updateVisualizerStatus('error', 'Visualizer connection failed - MIDI audio still works');
                                }
                            }, 2000);
                        }
                    }, 1000);
                }
            }, 500);
            
        } catch (error) {
            console.error('Error connecting to MIDI device:', error);
            updateStatus('midiStatus', 'Failed to connect to MIDI device', 'error');
        }
    }


    // MIDI Recording Buffer - FRONTEND ONLY (No WebSockets!)
    class MidiRecorder {
        constructor() {
            this.isRecording = false;
            this.recordedNotes = [];
            this.startTime = null;
            this.recordingDuration = 0;
            this.silenceTimeout = null;
            this.mode = 'time';
        }
        
        startRecording(mode = 'time', duration = 10) {
            this.isRecording = true;
            this.recordedNotes = [];
            this.startTime = performance.now();
            this.mode = mode;
            this.recordingDuration = duration * 1000; // Convert to milliseconds
            
            console.log(`üéπ MIDI Recording started (${mode} mode)`);
            
            if (mode === 'time') {
                // Stop after fixed duration
                setTimeout(() => {
                    if (this.isRecording) {
                        this.stopRecording();
                    }
                }, this.recordingDuration);
            } else if (mode === 'silence') {
                // Monitor for silence
                this.resetSilenceTimer();
            }
        }
        
        stopRecording() {
            if (!this.isRecording) return;
            
            this.isRecording = false;
            
            if (this.silenceTimeout) {
                clearTimeout(this.silenceTimeout);
                this.silenceTimeout = null;
            }
            
            const totalDuration = (performance.now() - this.startTime) / 1000;
            console.log(`üéπ MIDI Recording stopped - Duration: ${totalDuration.toFixed(1)}s, Notes: ${this.recordedNotes.length}`);
            
            return this.recordedNotes;
        }
        
        addNote(note, velocity, timestamp, isNoteOn) {
            if (!this.isRecording) return;
            
            const relativeTime = (timestamp - this.startTime) / 1000; // Convert to seconds
            
            this.recordedNotes.push({
                note: note,
                velocity: velocity,
                time: relativeTime,
                isNoteOn: isNoteOn
            });
            
            // Reset silence timer for silence mode
            if (this.mode === 'silence' && isNoteOn) {
                this.resetSilenceTimer();
            }
        }
        
        resetSilenceTimer() {
            if (this.silenceTimeout) {
                clearTimeout(this.silenceTimeout);
            }
            
            // Stop recording after 2 seconds of silence
            this.silenceTimeout = setTimeout(() => {
                if (this.isRecording) {
                    this.stopRecording();
                }
            }, 2000);
        }
        
        convertToMidiBlob() {
            if (this.recordedNotes.length === 0) {
                throw new Error('No notes recorded');
            }
            
            // Simple MIDI file creation
            // This creates a basic MIDI file with the recorded notes
            const midiData = this.createMidiData(this.recordedNotes);
            return new Blob([midiData], { type: 'audio/midi' });
        }
        
        createMidiData(notes) {
            // Very simplified MIDI file creation
            // In a production app, you'd use a proper MIDI library
            // For now, we'll create a minimal MIDI file structure
            
            const header = new Uint8Array([
                0x4D, 0x54, 0x68, 0x64, // "MThd"
                0x00, 0x00, 0x00, 0x06, // Header length
                0x00, 0x00, // Format 0
                0x00, 0x01, // 1 track
                0x00, 0x60  // 96 ticks per quarter note
            ]);
            
            const trackData = this.createTrackData(notes);
            const trackHeader = new Uint8Array([
                0x4D, 0x54, 0x72, 0x6B, // "MTrk"
                ...this.int32ToBytes(trackData.length)
            ]);
            
            // Combine header + track header + track data
            const midiFile = new Uint8Array(header.length + trackHeader.length + trackData.length);
            midiFile.set(header, 0);
            midiFile.set(trackHeader, header.length);
            midiFile.set(trackData, header.length + trackHeader.length);
            
            return midiFile;
        }
        
        createTrackData(notes) {
            const events = [];
            let currentTime = 0;
            
            // Sort notes by time
            const sortedNotes = [...notes].sort((a, b) => a.time - b.time);
            
            for (const note of sortedNotes) {
                const deltaTime = Math.max(0, Math.round((note.time - currentTime) * 96)); // Convert to ticks
                currentTime = note.time;
                
                // Add MIDI event
                const status = note.isNoteOn ? 0x90 : 0x80; // Note on/off on channel 1
                events.push(...this.variableLengthQuantity(deltaTime));
                events.push(status, note.note, note.velocity);
            }
            
            // End of track
            events.push(0x00, 0xFF, 0x2F, 0x00);
            
            return new Uint8Array(events);
        }
        
        variableLengthQuantity(value) {
            const bytes = [];
            bytes.unshift(value & 0x7F);
            value >>= 7;
            while (value > 0) {
                bytes.unshift((value & 0x7F) | 0x80);
                value >>= 7;
            }
            return bytes;
        }
        
        int32ToBytes(value) {
            return [
                (value >> 24) & 0xFF,
                (value >> 16) & 0xFF,
                (value >> 8) & 0xFF,
                value & 0xFF
            ];
        }
    }

    // Metronome Class using Web Audio API
    class Metronome {
        constructor() {
            this.isPlaying = false;
            this.bpm = 100;
            this.beatCount = 0;
            this.isCountingIn = false;
            this.countInBeat = 0;
            this.recordingStarted = false;
            this.audioContext = null;
            this.intervalId = null;
            this.nextNoteTime = 0;
            this.lookahead = 25.0;
            this.scheduleAheadTime = 0.1;
        }
        
        async initAudio() {
            if (!this.audioContext) {
                this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
                
                if (this.audioContext.state === 'suspended') {
                    await this.audioContext.resume();
                }
            }
        }
        
        playClick(time, isCountIn) {
            const osc = this.audioContext.createOscillator();
            const envelope = this.audioContext.createGain();
            
            osc.connect(envelope);
            envelope.connect(this.audioContext.destination);
            
            osc.frequency.value = isCountIn ? 800 : 400;
            
            envelope.gain.setValueAtTime(0, time);
            envelope.gain.linearRampToValueAtTime(0.3, time + 0.001);
            envelope.gain.exponentialRampToValueAtTime(0.001, time + 0.1);
            
            osc.start(time);
            osc.stop(time + 0.1);
        }
        
        nextNote() {
            const secondsPerBeat = 60.0 / this.bpm;
            this.nextNoteTime += secondsPerBeat;
            
            if (this.isCountingIn) {
                this.countInBeat++;
                this.updateVisualIndicator(this.countInBeat, true);
                
                if (this.countInBeat >= 4) {
                    this.isCountingIn = false;
                    this.beatCount = 0;
                    this.recordingStarted = true;
                    setTimeout(() => this.startMIDIRecording(), 50);
                }
            } else {
                this.beatCount++;
                this.updateVisualIndicator(this.beatCount, false);
            }
        }
        
        scheduleNote() {
            while (this.nextNoteTime < this.audioContext.currentTime + this.scheduleAheadTime) {
                this.playClick(this.nextNoteTime, this.isCountingIn);
                this.nextNote();
            }
        }
        
        scheduler() {
            this.scheduleNote();
            
            if (this.isPlaying) {
                this.intervalId = setTimeout(() => this.scheduler(), this.lookahead);
            }
        }
        
        async start(bpm, countIn = true) {
            try {
                await this.initAudio();
                
                this.bpm = bpm;
                this.beatCount = 0;
                this.countInBeat = 0;
                this.isCountingIn = countIn;
                this.recordingStarted = false;
                this.isPlaying = true;
                
                this.nextNoteTime = this.audioContext.currentTime;
                this.scheduler();
                
                console.log(`ü•Å Metronome started at ${bpm} BPM${countIn ? ' with count-in' : ''}`);
            } catch (error) {
                console.error('Error initializing metronome:', error);
                throw error;
            }
        }
        
        updateVisualIndicator(beat, isCountIn) {
            const beatCircle = document.getElementById('beatCircle');
            const beatCount = document.getElementById('beatCount');
            
            if (!beatCircle || !beatCount) return;
            
            beatCircle.classList.remove('active', 'count-in');
            beatCount.classList.remove('count-in', 'recording');
            
            if (isCountIn) {
                beatCircle.classList.add('count-in');
                beatCount.classList.add('count-in');
                beatCount.textContent = beat.toString();
            } else {
                beatCircle.classList.add('active');
                beatCount.classList.add('recording');
                beatCount.textContent = `Beat ${beat}`;
            }
            
            setTimeout(() => {
                beatCircle.classList.remove('active', 'count-in');
            }, 150);
        }
        
        stop() {
            if (this.isPlaying) {
                this.isPlaying = false;
                this.isCountingIn = false;
                this.recordingStarted = false;
                
                if (this.intervalId) {
                    clearTimeout(this.intervalId);
                    this.intervalId = null;
                }
                
                const beatCircle = document.getElementById('beatCircle');
                const beatCount = document.getElementById('beatCount');
                
                if (beatCircle && beatCount) {
                    beatCircle.classList.remove('active', 'count-in');
                    beatCount.classList.remove('count-in', 'recording');
                    beatCount.textContent = 'Ready';
                }
                
                console.log('ü•Å Metronome stopped');
            }
        }
        
        startMIDIRecording() {
            console.log('üéµ Starting MIDI recording after count-in...');
            
            // Calculate much longer buffer time to ensure we capture everything
            const currentTempo = 100; // Fixed tempo
            const beatsPerSecond = currentTempo / 60;
            const durationFor16Beats = 16 / beatsPerSecond;
            
            // Add 3 second buffer to absolutely ensure we don't cut off
            const bufferedDuration = durationFor16Beats + 3.0;
            
            console.log(`üéØ EXTENDED recording: ${bufferedDuration.toFixed(1)}s (${durationFor16Beats.toFixed(1)}s + 3s buffer) for 16 beats at ${currentTempo} BPM`);
            
            // Wait a tiny bit to ensure metronome timing is perfect
            setTimeout(() => {
                startDirectCapture(bufferedDuration);
            }, 50); // 50ms delay for perfect sync
        }
    }

    // Enhanced Piano Synthesizer Class - Controlled Reverb
    class PianoSynth {
        constructor() {
            this.audioContext = null;
            this.masterGain = null;
            this.dryGain = null;
            this.wetGain = null;
            this.reverbNode = null;
            this.activeNotes = new Map();
            this.volume = 0.7;
            this.reverbAmount = 0.15; // 15% reverb by default
            this.soundType = 'piano';
        }
        
        async init() {
            if (!this.audioContext) {
                this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
                
                // Create gain nodes for dry/wet mixing
                this.masterGain = this.audioContext.createGain();
                this.dryGain = this.audioContext.createGain();
                this.wetGain = this.audioContext.createGain();
                
                // Set initial volumes
                this.masterGain.gain.value = this.volume;
                this.updateReverbMix();
                
                // Create subtle reverb
                await this.createReverb();
                
                // Connect: dry signal bypasses reverb, wet signal goes through reverb
                this.dryGain.connect(this.masterGain);
                this.wetGain.connect(this.reverbNode);
                this.reverbNode.connect(this.masterGain);
                this.masterGain.connect(this.audioContext.destination);
                
                if (this.audioContext.state === 'suspended') {
                    await this.audioContext.resume();
                }
                
                console.log('üéπ Enhanced piano synthesizer initialized with controlled reverb');
            }
        }
        
        async createReverb() {
            // Create convolution reverb - MUCH more subtle
            this.reverbNode = this.audioContext.createConvolver();
            
            // Create shorter, more subtle impulse response
            const length = this.audioContext.sampleRate * 0.5; // Only 0.5 seconds
            const impulse = this.audioContext.createBuffer(2, length, this.audioContext.sampleRate);
            
            for (let channel = 0; channel < 2; channel++) {
                const channelData = impulse.getChannelData(channel);
                for (let i = 0; i < length; i++) {
                    const decay = Math.pow(1 - i / length, 3); // Faster decay
                    channelData[i] = (Math.random() * 2 - 1) * decay * 0.03; // Much quieter
                }
            }
            
            this.reverbNode.buffer = impulse;
        }
        
        updateReverbMix() {
            if (this.dryGain && this.wetGain) {
                // Mix between dry and wet signal
                this.dryGain.gain.value = 1 - this.reverbAmount;
                this.wetGain.gain.value = this.reverbAmount;
            }
        }
        
        midiNoteToFrequency(midiNote) {
            return 440 * Math.pow(2, (midiNote - 69) / 12);
        }
        
        createEnhancedPianoSound(frequency, startTime, duration = 3.0) {
            // Create multiple oscillators for rich harmonics
            const fundamental = this.audioContext.createOscillator();
            const harmonic2 = this.audioContext.createOscillator();
            const harmonic3 = this.audioContext.createOscillator();
            const subharmonic = this.audioContext.createOscillator();
            
            // Create filters for each oscillator
            const filter1 = this.audioContext.createBiquadFilter();
            const filter2 = this.audioContext.createBiquadFilter();
            const filter3 = this.audioContext.createBiquadFilter();
            const subFilter = this.audioContext.createBiquadFilter();
            
            // Create gain nodes for mixing
            const fundamentalGain = this.audioContext.createGain();
            const harmonic2Gain = this.audioContext.createGain();
            const harmonic3Gain = this.audioContext.createGain();
            const subGain = this.audioContext.createGain();
            const masterEnvelope = this.audioContext.createGain();
            
            // Configure oscillators based on sound type
            switch (this.soundType) {
                case 'piano':
                    fundamental.type = 'triangle';
                    harmonic2.type = 'sine';
                    harmonic3.type = 'sawtooth';
                    subharmonic.type = 'sine';
                    
                    fundamental.frequency.value = frequency;
                    harmonic2.frequency.value = frequency * 2;
                    harmonic3.frequency.value = frequency * 3;
                    subharmonic.frequency.value = frequency * 0.5;
                    
                    filter1.type = 'lowpass';
                    filter1.frequency.value = 2500;
                    filter1.Q.value = 1;
                    
                    filter2.type = 'bandpass';
                    filter2.frequency.value = 1500;
                    filter2.Q.value = 2;
                    
                    filter3.type = 'highpass';
                    filter3.frequency.value = 500;
                    filter3.Q.value = 1;
                    
                    subFilter.type = 'lowpass';
                    subFilter.frequency.value = 200;
                    subFilter.Q.value = 1;
                    
                    fundamentalGain.gain.value = 0.6;
                    harmonic2Gain.gain.value = 0.3;
                    harmonic3Gain.gain.value = 0.15;
                    subGain.gain.value = 0.4;
                    break;
                    
                case 'electric':
                    fundamental.type = 'sawtooth';
                    harmonic2.type = 'triangle';
                    harmonic3.type = 'square';
                    subharmonic.type = 'sine';
                    
                    fundamental.frequency.value = frequency;
                    harmonic2.frequency.value = frequency * 2;
                    harmonic3.frequency.value = frequency * 4;
                    subharmonic.frequency.value = frequency * 0.5;
                    
                    filter1.type = 'lowpass';
                    filter1.frequency.value = 1800;
                    filter1.Q.value = 3;
                    
                    fundamentalGain.gain.value = 0.7;
                    harmonic2Gain.gain.value = 0.4;
                    harmonic3Gain.gain.value = 0.2;
                    subGain.gain.value = 0.3;
                    break;
                    
                case 'organ':
                    fundamental.type = 'sawtooth';
                    harmonic2.type = 'square';
                    harmonic3.type = 'triangle';
                    subharmonic.type = 'square';
                    
                    fundamental.frequency.value = frequency;
                    harmonic2.frequency.value = frequency * 2;
                    harmonic3.frequency.value = frequency * 3;
                    subharmonic.frequency.value = frequency;
                    
                    filter1.type = 'lowpass';
                    filter1.frequency.value = 3500;
                    filter1.Q.value = 0.5;
                    
                    fundamentalGain.gain.value = 0.5;
                    harmonic2Gain.gain.value = 0.4;
                    harmonic3Gain.gain.value = 0.3;
                    subGain.gain.value = 0.6;
                    break;
                    
                case 'synth':
                    fundamental.type = 'square';
                    harmonic2.type = 'sawtooth';
                    harmonic3.type = 'triangle';
                    subharmonic.type = 'square';
                    
                    fundamental.frequency.value = frequency;
                    harmonic2.frequency.value = frequency * 1.5;
                    harmonic3.frequency.value = frequency * 0.75;
                    subharmonic.frequency.value = frequency * 0.5;
                    
                    filter1.type = 'bandpass';
                    filter1.frequency.value = 1200;
                    filter1.Q.value = 8;
                    
                    fundamentalGain.gain.value = 0.8;
                    harmonic2Gain.gain.value = 0.6;
                    harmonic3Gain.gain.value = 0.4;
                    subGain.gain.value = 0.5;
                    break;
            }
            
            // Connect the audio graph
            fundamental.connect(filter1);
            filter1.connect(fundamentalGain);
            
            harmonic2.connect(filter2);
            filter2.connect(harmonic2Gain);
            
            harmonic3.connect(filter3);
            filter3.connect(harmonic3Gain);
            
            subharmonic.connect(subFilter);
            subFilter.connect(subGain);
            
            // Connect to both dry and wet paths
            fundamentalGain.connect(masterEnvelope);
            harmonic2Gain.connect(masterEnvelope);
            harmonic3Gain.connect(masterEnvelope);
            subGain.connect(masterEnvelope);
            
            // Split signal to dry and wet paths
            masterEnvelope.connect(this.dryGain);  // Dry signal (no reverb)
            masterEnvelope.connect(this.wetGain);  // Wet signal (with reverb)
            
            // Create realistic ADSR envelope
            const attackTime = 0.005;
            const decayTime = 0.3;
            const sustainLevel = 0.4;
            const releaseTime = 1.2;
            
            masterEnvelope.gain.setValueAtTime(0, startTime);
            masterEnvelope.gain.linearRampToValueAtTime(0.9, startTime + attackTime);
            masterEnvelope.gain.exponentialRampToValueAtTime(sustainLevel, startTime + attackTime + decayTime);
            masterEnvelope.gain.exponentialRampToValueAtTime(0.001, startTime + duration);
            
            // Start all oscillators
            fundamental.start(startTime);
            harmonic2.start(startTime);
            harmonic3.start(startTime);
            subharmonic.start(startTime);
            
            // Stop all oscillators
            fundamental.stop(startTime + duration);
            harmonic2.stop(startTime + duration);
            harmonic3.stop(startTime + duration);
            subharmonic.stop(startTime + duration);
            
            return { 
                fundamental, harmonic2, harmonic3, subharmonic,
                masterEnvelope, filters: [filter1, filter2, filter3, subFilter]
            };
        }
        
        playNote(midiNote, velocity = 100) {
            if (!this.audioContext) return;
            
            const frequency = this.midiNoteToFrequency(midiNote);
            const startTime = this.audioContext.currentTime;
            const normalizedVelocity = Math.max(0.1, Math.min(1.0, velocity / 127));
            
            const sound = this.createEnhancedPianoSound(frequency, startTime, 4.0);
            sound.masterEnvelope.gain.value *= normalizedVelocity;
            
            this.activeNotes.set(midiNote, sound);
            
            console.log(`üéπ Playing note ${midiNote} (${frequency.toFixed(1)}Hz) at velocity ${velocity}`);
        }
        
        stopNote(midiNote) {
            if (this.activeNotes.has(midiNote)) {
                const sound = this.activeNotes.get(midiNote);
                const releaseTime = this.audioContext.currentTime;
                
                // Natural release envelope
                sound.masterEnvelope.gain.exponentialRampToValueAtTime(0.001, releaseTime + 0.8);
                
                this.activeNotes.delete(midiNote);
                console.log(`üéπ Stopping note ${midiNote}`);
            }
        }
        
        setVolume(volume) {
            this.volume = Math.max(0, Math.min(1, volume / 100));
            if (this.masterGain) {
                this.masterGain.gain.setTargetAtTime(this.volume, this.audioContext.currentTime, 0.1);
            }
        }
        
        setReverbAmount(amount) {
            this.reverbAmount = Math.max(0, Math.min(1, amount / 100));
            this.updateReverbMix();
            console.log(`üéπ Reverb amount changed to: ${(this.reverbAmount * 100).toFixed(0)}%`);
        }
        
        setSoundType(soundType) {
            this.soundType = soundType;
            console.log(`üéπ Piano sound changed to: ${soundType}`);
        }
        
        testSound() {
            // Play a nice chord progression
            this.playNote(60, 80); // C4
            setTimeout(() => this.playNote(64, 70), 150); // E4
            setTimeout(() => this.playNote(67, 70), 300); // G4
            setTimeout(() => this.playNote(72, 60), 450); // C5
        }
    }
    
    // Initialize objects
    metronome = new Metronome();
    pianoSynth = new PianoSynth();
    midiRecorder = new MidiRecorder();

    // MIDI Player Functions
    function initializeMidiPlayer() {
        midiPlayer = document.getElementById('arrangementPlayer');
        if (midiPlayer) {
            console.log('üéµ MIDI Player initialized');
            // Set playbackRate to match desired BPM (100) from default (120)
            midiPlayer.playbackRate = baseBPM / defaultBPM;
            updateMidiDebugInfo(`Playback rate: ${midiPlayer.playbackRate.toFixed(3)} for BPM ${baseBPM}`);
            updateMidiDebugInfo(`16-beat loop duration: ${getMidiLoopEnd().toFixed(2)}s`);

            midiPlayer.addEventListener('start', () => {
                updateMidiDebugInfo('Playback started');
                if (isMidiLooping) {
                    if (midiCheckLoopInterval) clearInterval(midiCheckLoopInterval);
                    midiCheckLoopInterval = setInterval(() => {
                        if (midiPlayer.currentTime !== undefined) {
                            const loopEnd = getMidiLoopEnd();
                            const loopStart = getMidiLoopStart();
                            // Trigger loop 200ms early to beat the stop
                            if (midiPlayer.currentTime >= loopEnd - 0.2) {
                                midiPlayer.currentTime = loopStart;
                                setTimeout(() => {
                                    if (!midiPlayer.playing) {
                                        midiPlayer.start();
                                        updateMidiDebugInfo('Player restarted after loop');
                                    }
                                }, 10); // Small delay to ensure time is set
                                updateMidiDebugInfo(`Loop: ${midiPlayer.currentTime.toFixed(2)}s -> ${loopStart.toFixed(2)}s`);
                            }
                        }
                    }, 5); // Check every 5ms for tighter control
                }
            });

            midiPlayer.addEventListener('stop', () => {
                updateMidiDebugInfo(`Stopped at ${midiPlayer.currentTime?.toFixed(2) || 'unknown'}s, Looping: ${isMidiLooping}`);
                if (midiCheckLoopInterval) {
                    clearInterval(midiCheckLoopInterval);
                    midiCheckLoopInterval = null;
                }
            });
        } else {
            console.error('‚ùå No MIDI player found');
            updateMidiDebugInfo('ERROR: MIDI player not found');
        }
    }

    function getMidiLoopStart() {
        return 0; // Always start from beginning
    }

    function getMidiLoopEnd() {
        // Fixed 16-beat duration at 100 BPM
        return (beatsPerLoop * 60) / baseBPM; // 9.6s for 16 beats at 100 BPM
    }

    function updateMidiDebugInfo(message) {
        const info = document.getElementById('midiPlayerInfo');
        if (info) {
            const timestamp = new Date().toLocaleTimeString();
            info.innerHTML += `[${timestamp}] ${message}<br>`;
            info.scrollTop = info.scrollHeight;
        }
    }

    function toggleMidiPlay() {
        if (midiPlayer) {
            if (midiPlayer.playing) {
                midiPlayer.stop();
            } else {
                midiPlayer.start();
            }
        }
    }

    function stopMidi() {
        if (midiPlayer) {
            midiPlayer.stop();
            midiPlayer.currentTime = 0;
            updateMidiDebugInfo('Reset to start');
        }
    }

    function toggleMidiLoop() {
        isMidiLooping = !isMidiLooping;
        document.getElementById('midiLoopStatus').textContent = `Loop: ${isMidiLooping ? 'ON' : 'OFF'}`;
        updateMidiDebugInfo(`Looping: ${isMidiLooping ? 'ON' : 'OFF'}`);
        
        // Clear interval when looping is turned off
        if (!isMidiLooping && midiCheckLoopInterval) {
            clearInterval(midiCheckLoopInterval);
            midiCheckLoopInterval = null;
        }
    }

    // Completely robust showMidiPlayer function that eliminates ALL path issues
    function showMidiPlayer(arrangementFilename) {
        const midiPlayerSection = document.getElementById('midiPlayerSection');
        const midiPlayer = document.getElementById('arrangementPlayer');
        
        if (midiPlayerSection && midiPlayer) {
            // COMPLETELY strip everything and get just the filename
            let justFilename = arrangementFilename;
            
            console.log('üîß DEBUG: Original input:', justFilename);
            
            // Remove any URL protocols
            justFilename = justFilename.replace(/^https?:\/\/[^\/]+/, '');
            
            // Remove any leading slashes
            justFilename = justFilename.replace(/^\/+/, '');
            
            // If it contains ANY path separators, just get the last part (filename only)
            if (justFilename.includes('/')) {
                justFilename = justFilename.split('/').pop();
            }
            
            // If it contains backslashes (Windows paths), get the last part
            if (justFilename.includes('\\')) {
                justFilename = justFilename.split('\\').pop();
            }
            
            // Remove any remaining path prefixes
            justFilename = justFilename.replace(/.*generated_arrangements[\/\\]/, '');
            
            // Final safety check - if it STILL has path separators, just get the last part
            while (justFilename.includes('/') || justFilename.includes('\\')) {
                justFilename = justFilename.split(/[\/\\]/).pop();
            }
            
            // Construct the clean path - ONLY use the filename
            const finalPath = `/generated_arrangements/${justFilename}`;
            
            console.log('üîß DEBUG: Extracted filename:', justFilename);
            console.log('üîß DEBUG: Final path:', finalPath);
            
            // Set the source
            midiPlayer.src = finalPath;
            
            // Show the player
            midiPlayerSection.style.display = 'block';
            
            // Initialize player if not already done
            initializeMidiPlayer();
            
            updateMidiDebugInfo(`Loaded: ${justFilename}`);
            updateMidiDebugInfo(`Path: ${finalPath}`);
            console.log('üéµ MIDI Player loaded:', finalPath);
            
            // Test if the file actually exists by making a fetch request
            fetch(finalPath, { method: 'HEAD' })
                .then(response => {
                    if (response.ok) {
                        updateMidiDebugInfo(`‚úÖ File confirmed accessible`);
                    } else {
                        updateMidiDebugInfo(`‚ùå File not found (${response.status})`);
                        console.error('File not accessible:', finalPath);
                    }
                })
                .catch(error => {
                    updateMidiDebugInfo(`‚ùå File check failed: ${error.message}`);
                    console.error('Error checking file:', error);
                });
        }
    }

    // Web MIDI API Functions
    async function loadDevices() {
        try {
            if (!navigator.requestMIDIAccess) {
                updateStatus('midiStatus', 'Web MIDI API not supported in this browser', 'error');
                const select = document.getElementById('deviceSelect');
                if (select) {
                    select.innerHTML = '<option>Web MIDI not supported</option>';
                }
                return;
            }
            
            midiAccess = await navigator.requestMIDIAccess();
            const inputs = Array.from(midiAccess.inputs.values());
            
            const select = document.getElementById('deviceSelect');
            if (!select) return;
            
            select.innerHTML = '';
            
            if (inputs.length === 0) {
                select.innerHTML = '<option>No MIDI devices found</option>';
            } else {
                inputs.forEach((input, index) => {
                    const option = document.createElement('option');
                    option.value = input.id;
                    option.textContent = `${input.name}`;
                    select.appendChild(option);
                });
                
                // AUTO-CONNECT: Automatically connect to the first available device
                if (inputs.length > 0) {
                    select.value = inputs[0].id;
                    console.log('üéπ Auto-connecting to first MIDI device:', inputs[0].name);
                    
                    // Small delay to ensure UI is updated, then auto-connect
                    setTimeout(() => {
                        connectDevice();
                    }, 100);
                }
            }
            
            console.log('üéπ Found MIDI inputs:', inputs.length);
        } catch (error) {
            console.error('Error accessing MIDI:', error);
            updateStatus('midiStatus', 'Failed to access MIDI devices', 'error');
            const select = document.getElementById('deviceSelect');
            if (select) {
                select.innerHTML = '<option>Error loading devices</option>';
            }
        }
    }
    
    function handleMIDIMessage(message) {
        const [command, note, velocity] = message.data;
        const timestamp = performance.now();
        
        // Note On (command 144-159, velocity > 0)
        if (command >= 144 && command <= 159 && velocity > 0) {
            // Play sound with perfect quality
            pianoSynth.playNote(note, velocity);
            
            // Record note if recording
            if (midiRecorder.isRecording) {
                midiRecorder.addNote(note, velocity, timestamp, true);
            }
        }
        // Note Off (command 128-143 or command 144-159 with velocity 0)
        else if ((command >= 128 && command <= 143) || 
                 (command >= 144 && command <= 159 && velocity === 0)) {
            // Stop sound naturally
            pianoSynth.stopNote(note);
            
            // Record note off if recording
            if (midiRecorder.isRecording) {
                midiRecorder.addNote(note, 0, timestamp, false);
            }
        }
    }
    
    // Recording Functions
    async function startCapture() {
        if (!midiInput) {
            updateStatus('captureStatus', 'Please connect a MIDI device first', 'error');
            return;
        }
        
        // Use default values since we removed the UI controls
        const enableMetronome = true; // Always enable metronome
        const tempo = 100; // Fixed tempo at 100 BPM
        
        if (enableMetronome) {
            updateStatus('captureStatus', 'ü•Å Count-in starting... Get ready!', 'analyzing');
            
            try {
                await metronome.start(tempo, true);
            } catch (error) {
                console.error('Error starting metronome:', error);
                updateStatus('captureStatus', 'Metronome error - starting recording without metronome', 'error');
                startDirectCapture();
            }
        } else {
            startDirectCapture();
        }
    }
    
    function startDirectCapture(predefinedDuration = null) {
        const captureModeSelect = document.getElementById('captureMode');
        if (!captureModeSelect) return;
        
        const mode = captureModeSelect.value;
        
        let duration;
        if (predefinedDuration) {
            // Use predefined duration (from metronome)
            duration = predefinedDuration;
        } else {
            // Calculate duration for manual start - use fixed tempo
            const currentTempo = 100; // Fixed tempo
            const beatsPerSecond = currentTempo / 60;
            const durationFor16Beats = 16 / beatsPerSecond;
            duration = mode === 'time' ? durationFor16Beats + 1.0 : 30.0; // Add buffer for manual mode too
        }
        
        console.log(`üéµ Recording for ${duration.toFixed(1)}s (mode: ${mode})`);
        
        // Start frontend MIDI recording
        midiRecorder.startRecording(mode, duration);
        
        updateStatus('captureStatus', 'üéµ Recording... Play your melody!', 'recording');
        
        // **NEW: GUARANTEED AUTO-STOP after exactly 16 bars (9.6 seconds)**
        const exactDurationFor16Bars = 10.1; // 16 beats at 100 BPM = 9.6 seconds
        const autoStopTimeout = setTimeout(() => {
            console.log('‚è∞ Auto-stopping recording after 16 bars (9.6s)');
            stopCapture(); // This will stop both metronome and MIDI recorder
        }, exactDurationFor16Bars * 1000); // Convert to milliseconds
        
        // Store the timeout ID so we can clear it if manually stopped
        window.currentAutoStopTimeout = autoStopTimeout;
        
        // Monitor recording status
        const statusInterval = setInterval(() => {
            if (!midiRecorder.isRecording) {
                clearInterval(statusInterval);
                
                // Clear the auto-stop timeout since recording already stopped
                if (window.currentAutoStopTimeout) {
                    clearTimeout(window.currentAutoStopTimeout);
                    window.currentAutoStopTimeout = null;
                }
                
                const notes = midiRecorder.recordedNotes;
                updateStatus('captureStatus', `‚úÖ Recording finished! ${notes.length} MIDI events captured`, 'ready');
                
                // Auto-analyze if notes were captured
                if (notes.length > 0) {
                    updateStatus('captureStatus', 'üì§ Uploading recorded MIDI for analysis...', 'analyzing');
                    uploadRecordedMIDI();
                }
            } else {
                const notes = midiRecorder.recordedNotes;
                const duration = (performance.now() - midiRecorder.startTime) / 1000;
                updateStatus('captureStatus', `üéµ Recording... ${notes.length} events, ${duration.toFixed(1)}s`, 'recording');
            }
        }, 100);
    }
    
    function stopCapture() {
        // Clear the auto-stop timeout if it exists
        if (window.currentAutoStopTimeout) {
            clearTimeout(window.currentAutoStopTimeout);
            window.currentAutoStopTimeout = null;
            console.log('üõë Cleared auto-stop timeout (manual stop)');
        }
        
        // Stop metronome
        if (metronome) {
            metronome.stop();
        }
        
        // Stop MIDI recording
        if (midiRecorder.isRecording) {
            midiRecorder.stopRecording();
        }
        
        updateStatus('captureStatus', '‚èπÔ∏è Recording stopped', 'ready');
    }
    
    // Upload recorded MIDI to backend
    async function uploadRecordedMIDI() {
        try {
            // Convert recorded notes to MIDI file
            const midiBlob = midiRecorder.convertToMidiBlob();
            
            // Create form data for upload
            const formData = new FormData();
            formData.append('file', midiBlob, 'recorded_melody.mid');
            
            // Upload to backend
            const response = await fetch(`${API_BASE}/analyze/melody`, {
                method: 'POST',
                body: formData
            });
            
            if (!response.ok) {
                throw new Error(`Upload failed: ${response.status}`);
            }
            
            const result = await response.json();
            
            updateStatus('captureStatus', '‚úÖ MIDI analyzed with auto-generated visualization!', 'ready');
            console.log('üéπ MIDI analyzed successfully:', result);
            
            // Store uploaded filename for analysis
            window.uploadedMidiResult = result;
            
            // AUTO-DISPLAY the analysis results with visualization
            displayAutoAnalysisResults(result);
            
        } catch (error) {
            console.error('Error uploading MIDI:', error);
            updateStatus('captureStatus', 'Failed to upload recorded MIDI', 'error');
        }
    }
    
    // Fixed displayAutoAnalysisResults - handles both chord progression and melody responses
    function displayAutoAnalysisResults(result) {
        const resultsSection = document.getElementById('results');
        const keyInfo = document.getElementById('keyInfo');
        const progressions = document.getElementById('progressions');
        const arrangementLink = document.getElementById('arrangementLink');
        const visualizationLink = document.getElementById('visualizationLink');
        
        if (!resultsSection || !keyInfo || !progressions || !arrangementLink || !visualizationLink) return;
        
        resultsSection.style.display = 'block';
        
        console.log('üîç DEBUG: Full result object:', result);
        console.log('üîç DEBUG: Detected type:', result.detected_type);
        console.log('üîç DEBUG: Analysis path:', result.analysis_path);
        
        // Display key information
        const detectedType = result.detected_type || 'unknown';
        const analysisPath = result.analysis_path || 'unknown';
        const key = result.key || 'C';
        
        keyInfo.innerHTML = 
            `<strong>Detected Type:</strong> ${detectedType.toUpperCase()}<br>
            <strong>Analysis Path:</strong> ${analysisPath}<br>
            <strong>Key:</strong> ${key}`;
        
        // Handle different response formats based on detection type
        if (detectedType === 'chord_progression') {
            // CHORD PROGRESSION PATH - Single progression
            console.log('üìä Displaying chord progression results');
            
            const chordProgression = result.chord_progression || ['C', 'F', 'G', 'C'];
            
            let progressionsHtml = '<h4>üéº Detected Chord Progression:</h4>';
            progressionsHtml += `<div style="margin: 10px 0; padding: 15px; border-radius: 8px; background: #e3f2fd;">
                <strong>Chord Progression:</strong> 
                <div class="chord-progression">${chordProgression.join(' ‚Üí ')}</div>
                <small>Analysis: Direct chord detection from polyphonic input</small>
            </div>`;
            
            // Show chord analysis details if available
            if (result.chord_analysis) {
                const segments = result.chord_analysis.segments || [];
                const timingAdjustments = result.chord_analysis.timing_adjustments || [];
                
                progressionsHtml += `<div style="margin: 10px 0; padding: 10px; border-radius: 8px; background: #f5f5f5;">
                    <small><strong>Analysis Details:</strong><br>
                    ‚Ä¢ Segments analyzed: ${segments.length}<br>
                    ‚Ä¢ Timing adjustments: ${timingAdjustments.length} beats<br>
                    ‚Ä¢ Tolerance used: ${result.chord_analysis.tolerance_used ? 'Yes' : 'No'}</small>
                </div>`;
            }
            
            progressions.innerHTML = progressionsHtml;
            
        } else {
            // MELODY PATH - Multiple harmonization options
            console.log('üìä Displaying melody harmonization results');
            
            if (result.harmonizations) {
                // Calculate max confidence for display
                const confidences = Object.values(result.harmonizations).map(h => h.confidence || 0);
                const maxConfidence = Math.max(...confidences) / 100;
                
                keyInfo.innerHTML += `<br><strong>Confidence:</strong> ${maxConfidence.toFixed(2)}`;
                
                let progressionsHtml = '<h4>üéµ 4 Harmonization Options (8 chords each):</h4>';
                Object.entries(result.harmonizations).forEach(([style, data]) => {
                    const styleDisplayName = style.replace('_', '/').replace(/\b\w/g, l => l.toUpperCase());
                    const progression = data.progression || ['C', 'C', 'C', 'C', 'C', 'C', 'C', 'C'];
                    const confidence = data.confidence || 0;
                    
                    progressionsHtml += `<div style="margin: 10px 0; padding: 10px; border-radius: 8px; background: #f0f0f0;">
                        <strong>${styleDisplayName}:</strong> 
                        <div class="chord-progression">${progression.join(' ‚Üí ')}</div>
                        <small>Confidence: ${confidence.toFixed(1)}% | Forced 8-chord analysis</small>
                    </div>`;
                });
                progressions.innerHTML = progressionsHtml;
            } else {
                // Fallback if no harmonizations (shouldn't happen for melody path)
                progressions.innerHTML = '<h4>‚ö†Ô∏è No harmonization data available</h4>';
            }
        }
        
        // Generic arrangement link
        arrangementLink.innerHTML = '<em>Use "Generate Full Arrangement" button below to create MIDI arrangement</em>';
        
        // Handle visualization links
        let visualizationHtml = '';
        
        // Chord/Melody detection visualization (always present)
        if (result.chord_melody_detection && result.chord_melody_detection.download_url) {
            visualizationHtml += `<strong>üîç Type Detection:</strong> <a href="${API_BASE}${result.chord_melody_detection.download_url}" target="_blank" rel="noopener">View Detection Analysis</a><br>`;
        }
        
        // Main analysis visualization
        if (result.visualization && result.visualization.success && result.visualization.download_url) {
            const vizType = result.visualization.type || 'analysis';
            const vizLabel = vizType === 'chord_progression' ? 'Chord Progression Chart' : 'Harmonization Options Chart';
            visualizationHtml += `<strong>üìä ${vizLabel}:</strong> <a href="${API_BASE}${result.visualization.download_url}" target="_blank" rel="noopener">View Analysis Chart</a>`;
        }
        
        if (visualizationHtml) {
            visualizationLink.innerHTML = visualizationHtml;
        } else {
            visualizationLink.innerHTML = '<em>Visualization generation failed</em>';
        }
        
        console.log('‚úÖ Auto-analysis results displayed successfully');
    }
    
    // Fixed analyzeAndGenerate - handles both chord progression and melody results
    async function analyzeAndGenerate() {
        if (!window.uploadedMidiResult) {
            updateStatus('analysisStatus', 'Please record a melody first', 'error');
            return;
        }
        
        const harmonySelect = document.getElementById('harmonyStyle');
        const bassSlider = document.getElementById('bassComplexity');
        const drumSlider = document.getElementById('drumComplexity');
        
        if (!harmonySelect || !bassSlider || !drumSlider) return;
        
        const style = harmonySelect.value;
        const bassComplexity = parseInt(bassSlider.value);
        const drumComplexity = parseInt(drumSlider.value);
        
        updateStatus('analysisStatus', 'üéµ Generating full arrangement...', 'analyzing');
        
        try {
            const result = window.uploadedMidiResult;
            const detectedType = result.detected_type || 'melody';
            
            console.log('üîß DEBUG: Detected type for arrangement:', detectedType);
            console.log('üîß DEBUG: Full result object:', result);
            
            let selectedProgression;
            let styleMap = {};
            
            if (detectedType === 'chord_progression') {
                // CHORD PROGRESSION PATH - Use the detected progression
                console.log('üéº Using detected chord progression for arrangement');
                selectedProgression = result.chord_progression || ['C', 'F', 'G', 'C', 'Am', 'F', 'G', 'C'];
                
                // For chord progressions, all "styles" use the same detected progression
                styleMap = {
                    "simple_pop": selectedProgression,
                    "folk_acoustic": selectedProgression,
                    "bass_foundation": selectedProgression,
                    "phrase_foundation": selectedProgression
                };
                
                console.log('üîß Using chord progression:', selectedProgression);
                
            } else {
                // MELODY PATH - Use harmonizations as before
                console.log('üéº Using melody harmonizations for arrangement');
                
                if (!result.harmonizations) {
                    throw new Error('No harmonizations found in melody result');
                }
                
                styleMap = {
                    "simple_pop": result.harmonizations.simple_pop?.progression || ['C', 'F', 'G', 'C', 'Am', 'F', 'G', 'C'],
                    "folk_acoustic": result.harmonizations.folk_acoustic?.progression || ['C', 'F', 'G', 'C', 'Am', 'F', 'G', 'C'],
                    "bass_foundation": result.harmonizations.bass_foundation?.progression || ['C', 'F', 'G', 'C', 'Am', 'F', 'G', 'C'],
                    "phrase_foundation": result.harmonizations.phrase_foundation?.progression || ['C', 'F', 'G', 'C', 'Am', 'F', 'G', 'C']
                };
                
                selectedProgression = styleMap[style];
                console.log('üîß Selected harmonization style:', style);
            }
            
            console.log('üîß Sending request with progression:', selectedProgression);
            
            // Generate arrangement from the chord progression
            const response = await fetch(`${API_BASE}/generate/arrangement`, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({
                    chord_progression: selectedProgression,
                    bpm: 100,
                    bass_complexity: bassComplexity,
                    drum_complexity: drumComplexity,
                    hi_hat_divisions: 2,
                    snare_beats: [2, 4]
                })
            });
            
            if (!response.ok) {
                const errorText = await response.text();
                console.error('Backend error response:', errorText);
                throw new Error(`Server error: ${response.status} - ${errorText}`);
            }
            
            const arrangementResult = await response.json();
            
            console.log('üîß Backend response full object:', JSON.stringify(arrangementResult, null, 2));
            console.log('üîß Backend output_file field:', arrangementResult.output_file);
            
            if (arrangementResult.output_file) {
                // Pass the raw filename to showMidiPlayer - it will handle all cleaning
                showMidiPlayer(arrangementResult.output_file);
                
                // Create result object for display (handle both types)
                let keyConfidence = 0.75; // Default confidence
                
                if (detectedType === 'melody' && result.harmonizations) {
                    // Calculate confidence from harmonizations
                    const confidences = Object.values(result.harmonizations)
                        .map(h => h?.confidence || 0)
                        .filter(c => c > 0);
                    keyConfidence = confidences.length > 0 ? Math.max(...confidences) / 100 : 0.75;
                }
                
                const fullResult = {
                    success: true,
                    key: result.key || 'C',
                    key_confidence: keyConfidence,
                    chord_progressions: styleMap,
                    arrangement_file: arrangementResult.output_file.split('/').pop(), // Just filename for download link
                    visualization_file: null,
                    visualization_url: null,
                    detected_type: detectedType,
                    analysis_path: result.analysis_path || detectedType
                };
                
                updateStatus('analysisStatus', '‚úÖ Analysis and arrangement complete!', 'ready');
                displayFullResults(fullResult);
                
            } else {
                console.error('No output_file in response:', arrangementResult);
                updateStatus('analysisStatus', `‚ùå ${arrangementResult.message || 'No arrangement file returned'}`, 'error');
            }
        } catch (error) {
            console.error('Error in analyzeAndGenerate:', error);
            updateStatus('analysisStatus', `Analysis error: ${error.message}`, 'error');
        }
    }
    
    // Display Functions
    function displayFullResults(result) {
        const resultsSection = document.getElementById('results');
        const keyInfo = document.getElementById('keyInfo');
        const progressions = document.getElementById('progressions');
        const arrangementLink = document.getElementById('arrangementLink');
        const visualizationLink = document.getElementById('visualizationLink');
        
        if (!resultsSection || !keyInfo || !progressions || !arrangementLink || !visualizationLink) return;
        
        resultsSection.style.display = 'block';
        
        keyInfo.innerHTML = 
            `<strong>Detected Key:</strong> ${result.key} (confidence: ${result.key_confidence.toFixed(2)})`;
        
        let progressionsHtml = '<h4>Chord Progressions:</h4>';
        Object.entries(result.chord_progressions).forEach(([style, chords]) => {
            progressionsHtml += `<div>
                <strong>${style}:</strong> 
                <div class="chord-progression">${chords.join(' ‚Üí ')}</div>
            </div>`;
        });
        progressions.innerHTML = progressionsHtml;
        
        if (result.arrangement_file) {
            arrangementLink.innerHTML = 
                `<strong>Generated Arrangement:</strong> <a href="/generated_arrangements/${result.arrangement_file}" download>üì• Download MIDI (${result.arrangement_file})</a>`;
        } else {
            arrangementLink.innerHTML = '<em>No arrangement file generated</em>';
        }
        
        if (result.visualization_file) {
            visualizationLink.innerHTML = 
                `<strong>Visualization:</strong> <a href="${API_BASE}${result.visualization_url}" target="_blank" rel="noopener">üìä View Chord Progression Chart</a>`;
        } else {
            visualizationLink.innerHTML = '';
        }
    }
    
    // Utility Functions
    function updateStatus(elementId, message, type) {
        const element = document.getElementById(elementId);
        if (!element) return;
        
        element.textContent = message;
        element.className = `status ${type}`;
    }

    // Initialize everything
    document.addEventListener('DOMContentLoaded', function() {
        console.log('üöÄ DOM loaded, initializing...');
        
        // Initialize objects
        pianoSynth = new PianoSynth();
        midiRecorder = new MidiRecorder();
        
        // Start spectrum detection
        setTimeout(() => findSpectrumInstance(), 1000);
        
        // Load MIDI devices
        loadDevices();
        
        // Setup event listeners for sliders
        const bassComplexity = document.getElementById('bassComplexity');
        const drumComplexity = document.getElementById('drumComplexity');
        const bassValue = document.getElementById('bassValue');
        const drumValue = document.getElementById('drumValue');
        
        if (bassComplexity && bassValue) {
            bassComplexity.addEventListener('input', function(e) {
                bassValue.textContent = e.target.value;
            });
        }
        
        if (drumComplexity && drumValue) {
            drumComplexity.addEventListener('input', function(e) {
                drumValue.textContent = e.target.value;
            });
        }
        
        // Piano controls
        const pianoVolume = document.getElementById('pianoVolume');
        const pianoSound = document.getElementById('pianoSound');
        const volumeValue = document.getElementById('volumeValue');
        
        if (pianoVolume && volumeValue) {
            pianoVolume.addEventListener('input', function(e) {
                const volume = parseInt(e.target.value);
                volumeValue.textContent = volume + '%';
                pianoSynth.setVolume(volume);
            });
        }
        
        if (pianoSound) {
            pianoSound.addEventListener('change', function(e) {
                pianoSynth.setSoundType(e.target.value);
            });
        }
    });

    // Make functions globally accessible
    window.connectDevice = connectDevice;
    window.loadDevices = loadDevices;
    window.startCapture = startCapture;
    window.stopCapture = stopCapture;
    window.analyzeAndGenerate = analyzeAndGenerate;
    window.toggleMidiPlay = toggleMidiPlay;
    window.stopMidi = stopMidi;
    window.toggleMidiLoop = toggleMidiLoop;
    window.retryVisualizerConnection = retryVisualizerConnection;
</script>
</body>
</html>