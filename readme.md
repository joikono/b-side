# MIDI Analysis API

A modern FastAPI-based MIDI analysis and arrangement generation system with voice integration and frontend support.

## ğŸš€ Quick Start

1. **Install Dependencies**
   ```bash
   pip install -r requirements.txt
   ```

2. **Configure Environment**
   ```bash
   cp .env.example .env
   # Edit .env with your OpenAI API key for voice features
   ```

3. **Run the Application**
   ```bash
   python main.py
   ```

4. **Access the API**
   - API Server: http://localhost:8000
   - Interactive Documentation: http://localhost:8000/docs
   - Frontend: Open `astro-midi-app/` directory

## ğŸ“ Project Structure

```
â”œâ”€â”€ app/                    # Refactored FastAPI application
â”‚   â”œâ”€â”€ config.py          # Configuration settings
â”‚   â”œâ”€â”€ main.py            # FastAPI app and routes
â”‚   â”œâ”€â”€ core/              # Core services and utilities
â”‚   â”œâ”€â”€ models/            # Pydantic schemas
â”‚   â”œâ”€â”€ services/          # Business logic services
â”‚   â””â”€â”€ utils/             # Helper functions
â”œâ”€â”€ astro-midi-app/        # Frontend application
â”œâ”€â”€ main.py                # Application entry point
â”œâ”€â”€ requirements.txt       # Python dependencies
â””â”€â”€ .env.example          # Environment configuration template
```

## ğŸµ Features

- **MIDI Analysis**: Automatic chord progression and melody detection
- **8-Chord Harmonization**: Forced 8-chord analysis for consistent results
- **Arrangement Generation**: AI-powered backing track creation
- **Voice Commands**: OpenAI-powered intent classification
- **Visualization**: Real-time chord and melody visualization
- **File Processing**: MIDI duration fixing and optimization

## ğŸ¤– AI Integration

- **OpenAI Whisper**: Voice transcription (configurable)
- **OpenAI GPT**: Intent classification and conversational AI
- **Magenta**: MIDI arrangement generation (when available)

## ğŸ”§ Development

The application runs in mock mode when Magenta dependencies are not available, allowing for development and testing of the API structure.



AVAILABLE MODELS:
âœ… melody_rnn_sequence_generator - Available
ğŸµ Available melody models: ['basic_rnn', 'mono_rnn', 'lookback_rnn', 'attention_rnn']

==================================================
âœ… improv_rnn_sequence_generator - Available
ğŸ¸ Available improv models: ['basic_improv', 'attention_improv', 'chord_pitches_improv']

==================================================
âœ… drums_rnn_sequence_generator - Available
ğŸ¥ Available drum models: ['one_drum', 'drum_kit']

==================================================
ğŸ” Checking what Magenta models are installed...
ğŸ“ Available model directories: ['arbitrary_image_stylization', 'coconet', 'drums_rnn', 'gansynth', 'image_stylization', 'improv_rnn', 'latent_transfer', 'melody_rnn', 'music_vae', 'nsynth', 'onsets_frames_transcription', 'performance_rnn', 'pianoroll_rnn_nade', 'piano_genie', 'polyphony_rnn', 'rl_tuner', 'score2perf', 'shared', 'sketch_rnn', 'svg_vae', '__pycache__']